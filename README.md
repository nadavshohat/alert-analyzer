# Alert Analyzer

AI-powered Kubernetes crash analysis using Groundcover + AWS Bedrock Claude.

Automatically detects pod crashes, analyzes logs and traces, and sends enriched Slack alerts with root cause analysis and actionable recommendations.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Groundcover Clickhouse                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ events      â”‚  â”‚ logs        â”‚  â”‚ traces      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Alert Analyzer (Python Pod)                 â”‚
â”‚                                                          â”‚
â”‚  1. Poll events  â†’  2. Fetch logs/traces  â†’  3. Research â”‚
â”‚                                                          â”‚
â”‚  4. Analyze with Claude  â†’  5. Send to Slack            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                    â”‚
          â–¼                                    â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ AWS Bedrock  â”‚                    â”‚    Slack     â”‚
   â”‚ (Claude)     â”‚                    â”‚  (Webhook)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

- **Crash Detection**: Polls Groundcover Clickhouse for `CrashLoopBackOff`, `OOMKilled`, `Unhealthy`, etc.
- **Log Analysis**: Fetches recent container logs for context
- **Trace Analysis**: Identifies slow operations that may cause health check failures
- **Web Research**: Searches DuckDuckGo for error solutions
- **Pod Inspection**: Reads config files (package.json, etc.) from crashing pods
- **AI Analysis**: Uses Claude to determine root cause and recommendations
- **Slack Notifications**: Rich mrkdwn formatted alerts with deep links to Groundcover

## Example Alert

```
ğŸŸ¡ Unhealthy: solar-service

Summary
Event loop blocked by synchronous operations causing health check timeouts.

Findings
â€¢ Event: Unhealthy
  Namespace: prod
  Pod: solar-service-5dc7b8f7b4-bnlt5
  Message: Readiness probe failed: connection refused

Root Cause
Batch operations taking 90-100+ seconds are blocking the Node.js event loop,
preventing the health check endpoint from responding.

Recommended Action
Offload batch data processing to worker threads or a queue-based service.

Last seen: 09:17 | View in Groundcover
```

## Configuration

All configuration via environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `CLICKHOUSE_HOST` | `groundcover-clickhouse` | Clickhouse hostname |
| `CLICKHOUSE_PORT` | `8123` | Clickhouse HTTP port |
| `CLICKHOUSE_USER` | `default` | Clickhouse username |
| `CLICKHOUSE_PASSWORD` | - | Clickhouse password |
| `CLICKHOUSE_DATABASE` | `groundcover` | Clickhouse database |
| `POLL_INTERVAL_SECONDS` | `30` | How often to poll for events |
| `DEDUP_WINDOW_SECONDS` | `300` | Suppress duplicate alerts within this window |
| `LOG_LOOKBACK_MINUTES` | `30` | How far back to fetch logs |
| `EXCLUDE_NAMESPACES` | `kube-system,groundcover` | Namespaces to ignore |
| `EVENT_REASONS` | `CrashLoopBackOff,OOMKilled,...` | Event types to monitor |
| `BEDROCK_REGION` | `us-west-2` | AWS region for Bedrock |
| `BEDROCK_MODEL` | `anthropic.claude-sonnet-4-20250514-v1:0` | Claude model ID |
| `SLACK_WEBHOOK_URL` | - | Slack incoming webhook URL |
| `GROUNDCOVER_BASE_URL` | `https://app.groundcover.com` | Groundcover UI URL |
| `GROUNDCOVER_TENANT_UUID` | - | Your Groundcover tenant ID |
| `CLUSTER_NAME` | - | Kubernetes cluster name |

## Deployment

### Prerequisites

1. **Groundcover** installed in your cluster (provides Clickhouse with events/logs/traces)
2. **AWS Bedrock** access with Claude enabled
3. **Slack webhook** URL for notifications

### IAM Role (for IRSA)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel",
        "bedrock:InvokeModelWithResponseStream"
      ],
      "Resource": "arn:aws:bedrock:*::foundation-model/anthropic.*"
    }
  ]
}
```

### Deploy to Kubernetes

1. Update `k8s/configmap.yaml` with your configuration
2. Apply manifests:

```bash
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/deployment.yaml
```

### Build Docker Image

```bash
docker build -t alert-analyzer:latest .
docker tag alert-analyzer:latest <your-ecr-repo>/alert-analyzer:latest
docker push <your-ecr-repo>/alert-analyzer:latest
```

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # Entry point, polling loop
â”‚   â”œâ”€â”€ clickhouse.py    # Clickhouse queries (events, logs, traces)
â”‚   â”œâ”€â”€ analyzer.py      # Bedrock Claude analysis
â”‚   â”œâ”€â”€ notifier.py      # Slack notifications
â”‚   â”œâ”€â”€ research.py      # Web search + pod file reading
â”‚   â””â”€â”€ config.py        # Configuration
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml  # K8s Deployment, ServiceAccount, RBAC
â”‚   â””â”€â”€ configmap.yaml   # ConfigMap + Secret
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## How It Works

1. **Poll**: Every 30s, query Clickhouse `events` table for Warning events
2. **Deduplicate**: Skip if same workload/reason alerted within dedup window
3. **Fetch Context**: Get logs and slowest traces for the workload
4. **Research**: Search web for error solutions, read pod config files
5. **Analyze**: Send all context to Claude for root cause analysis
6. **Notify**: Format and send Slack message with findings

## Cost Estimate

| Scenario | Input Tokens | Output Tokens | Cost (Claude Sonnet) |
|----------|--------------|---------------|----------------------|
| 1 crash | ~4,000 | ~500 | ~$0.02 |
| 10 crashes/day | ~40,000 | ~5,000 | ~$0.20/day |

## License

MIT
